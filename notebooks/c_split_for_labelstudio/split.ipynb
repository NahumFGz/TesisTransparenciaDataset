{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_images_in_path(path, recursive=True, extensions=('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.webp', '.tiff')):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(extensions):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "        if not recursive:\n",
    "            break  # No seguir en subdirectorios\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_size(model_name: str):\n",
    "    name = model_name.lower()\n",
    "    if name in [\n",
    "        'vgg16', 'resnet50', 'densenet121',\n",
    "        'mobilenet_v2', 'googlenet', 'efficientnet_b0'\n",
    "    ]:\n",
    "        return (224, 224)\n",
    "    elif name == 'inception_v3':\n",
    "        return (299, 299)\n",
    "    else:\n",
    "        return (224, 224)  # valor por defecto\n",
    "\n",
    "def get_model(model_name, num_classes):\n",
    "    if model_name == 'mobilenet_v2':\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo '{model_name}' no soportado en este script.\")\n",
    "    return model\n",
    "\n",
    "def predict(image_path, model_path, model_name, data_dir, device=None, show=False):\n",
    "    device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Obtener clases\n",
    "    dataset = datasets.ImageFolder(data_dir)\n",
    "    class_names = dataset.classes\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    # Transformaciones\n",
    "    input_size = get_input_size(model_name)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Preparar imagen\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Cargar modelo y pesos\n",
    "    model = get_model(model_name, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Predicci√≥n\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        predicted_class = class_names[pred.item()]\n",
    "\n",
    "    if show:\n",
    "        print(f\"‚úÖ Predicci√≥n: {predicted_class}\")\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Predicci√≥n: {predicted_class}\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios base\n",
    "data_org = \"/home/nahumfg/Projects/GithubProjects/TesisTransparenciaDataset/data/a_org\"\n",
    "data_for_label_studio = \"/home/nahumfg/Projects/GithubProjects/TesisTransparenciaDataset/data/c_split_for_labelstudio\"\n",
    "\n",
    "# Rutas de destino para cada clase\n",
    "asistencia_dir = os.path.join(data_for_label_studio, \"asistencia\")\n",
    "votacion_dir = os.path.join(data_for_label_studio, \"votacion\")\n",
    "\n",
    "# Aseguramos que existan estos directorios\n",
    "os.makedirs(asistencia_dir, exist_ok=True)\n",
    "os.makedirs(votacion_dir, exist_ok=True)\n",
    "\n",
    "# Listamos todas las im√°genes en subdirectorios de data_org\n",
    "all_images = list_images_in_path(data_org, recursive=True)\n",
    "total_images = len(all_images)\n",
    "\n",
    "# Contadores para renombrar\n",
    "count_asistencia = 0\n",
    "count_votacion = 0\n",
    "max_images_per_class = 200  # S√≥lo queremos 200 de cada clase\n",
    "\n",
    "# Modelo y ruta de pesos\n",
    "model_path = \"../b_classification/mobilenet_v2_best_parallel.pth\"\n",
    "model_name = \"mobilenet_v2\"\n",
    "data_dir_for_classes = \"../../data/a_org\"  # Para obtener las clases\n",
    "\n",
    "# Iteramos sobre todas las im√°genes\n",
    "for i, img_path in enumerate(all_images, start=1):\n",
    "    # Obtenemos la predicci√≥n\n",
    "    pred_class = predict(\n",
    "        image_path=img_path,\n",
    "        model_path=model_path,\n",
    "        model_name=model_name,\n",
    "        data_dir=data_dir_for_classes, \n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        show=False\n",
    "    )\n",
    "\n",
    "    print(f\"[{i}/{total_images}] Procesando: {img_path} ‚Üí Clase: {pred_class}\")\n",
    "\n",
    "    # --- Copiamos s√≥lo si a√∫n no llegamos a 200 ---\n",
    "    if pred_class == 'asistencia':\n",
    "        if count_asistencia < max_images_per_class:\n",
    "            count_asistencia += 1\n",
    "            new_filename = f\"{str(count_asistencia).zfill(3)}_asistencia.jpg\"\n",
    "            new_path = os.path.join(asistencia_dir, new_filename)\n",
    "            shutil.copy2(img_path, new_path)\n",
    "            print(f\"   üìÅ Copiada a: {new_path}\")\n",
    "        else:\n",
    "            print(\"   ‚õî Ya se alcanzaron las 200 im√°genes de 'asistencia'. Ignorando...\")\n",
    "\n",
    "    elif pred_class == 'votacion':\n",
    "        if count_votacion < max_images_per_class:\n",
    "            count_votacion += 1\n",
    "            new_filename = f\"{str(count_votacion).zfill(3)}_votacion.jpg\"\n",
    "            new_path = os.path.join(votacion_dir, new_filename)\n",
    "            shutil.copy2(img_path, new_path)\n",
    "            print(f\"   üìÅ Copiada a: {new_path}\")\n",
    "        else:\n",
    "            print(\"   ‚õî Ya se alcanzaron las 200 im√°genes de 'votacion'. Ignorando...\")\n",
    "\n",
    "    else:\n",
    "        print(\"   ‚õî Etiqueta 'otros' detectada. Imagen ignorada.\")\n",
    "\n",
    "print(\"\\n‚úÖ Proceso de clasificaci√≥n y copiado finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tesisdataset",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
